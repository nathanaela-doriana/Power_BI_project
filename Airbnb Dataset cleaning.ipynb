{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created merged CSV\n",
      "5952\n"
     ]
    }
   ],
   "source": [
    "## UNIFICATION OF ALL THE CSV FILES AND FULL DATASET LOAD\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "#Read all the files in the directory\n",
    "file_paths = glob.glob(\"/Users/francescavasta/Desktop/ADSEM/II YEAR I SEM/UE 1 - Advanced programming/module 2 DATA VISUALIZATION/annonces csv/*.csv\")\n",
    "\n",
    "# Unify all the CSV in a unique DF\n",
    "dfs_linkedin = [pd.read_csv(file) for file in file_paths]\n",
    "merged_dfs_linkedin = pd.concat(dfs_linkedin, ignore_index = False) #only possible if all the csv have same number of columns, same name same order\n",
    "\n",
    "#Save the result in a unique file CSV\n",
    "merged_dfs_linkedin.to_csv(\"merged_annonces.csv\",index= False)\n",
    "print(\"created merged CSV\")\n",
    "print(merged_dfs_linkedin.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_dfs_linkedin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 URL  \\\n",
      "0  https://www.airbnb.fr/rooms/120514970925836693...   \n",
      "1  https://www.airbnb.fr/rooms/35018780?adults=1&...   \n",
      "2  https://www.airbnb.fr/rooms/104841383201487965...   \n",
      "3  https://www.airbnb.fr/rooms/43532792?adults=1&...   \n",
      "4  https://www.airbnb.fr/rooms/118375854256253325...   \n",
      "\n",
      "                Type of Accomodation                   Address    Travelers  \\\n",
      "0          Logement entier : cabane            Traînel, France  2 voyageurs   \n",
      "1                            Grotte    Noyers-sur-Cher, France  4 voyageurs   \n",
      "2     Logement entier : appartement              Rouen, France  2 voyageurs   \n",
      "3  Logement entier : maison d'hôtes              Ussel, France  2 voyageurs   \n",
      "4     Logement entier : hébergement       Valras-Plage, France  2 voyageurs   \n",
      "\n",
      "         Rooms                        Bathrooms                 Rating  \\\n",
      "0  · 1 chambre                · 1 salle de bain  4,97 étoile(s) sur 5.   \n",
      "1  · 1 chambre                · 1 salle de bain  4,82 étoile(s) sur 5.   \n",
      "2  · 1 chambre  · 1 salle de bain et 1 toilette  4,93 étoile(s) sur 5.   \n",
      "3  · 1 chambre                · 1 salle de bain  4,93 étoile(s) sur 5.   \n",
      "4  · 1 chambre               · 2 salles de bain  4,93 étoile(s) sur 5.   \n",
      "\n",
      "  Number of comments Price per night                      Free cancellation  \\\n",
      "0    61 commentaires           115 €   Annulation gratuite avant le 21 janv   \n",
      "1   417 commentaires           152 €                          Not specified   \n",
      "2   165 commentaires           120 €                   Claire est Superhôte   \n",
      "3   457 commentaires            32 €   Annulation gratuite avant le 11 janv   \n",
      "4    84 commentaires           207 €  Annulation gratuite pendant 48 heures   \n",
      "\n",
      "                        Host                                  Host experience  \\\n",
      "0              Hôte : Julien  Superhôte · 5 mois d'expérience en tant qu'hôte   \n",
      "1            Hôte : Sandrine                   Superhôte · Hôte depuis 10 ans   \n",
      "2              Hôte : Claire                    Superhôte · Hôte depuis 7 ans   \n",
      "3          Hôte : Christophe                    Superhôte · Hôte depuis 5 ans   \n",
      "4  Hôte : Amandine Et Maxime                    Superhôte · Hôte depuis 3 ans   \n",
      "\n",
      "                                            Comments  \n",
      "0  Ce logement fait partie des 5 % de logements p...  \n",
      "1  Ma copine et moi avons passe 3 jours dans cett...  \n",
      "2  L'un des logements préférés des voyageurs sur ...  \n",
      "3  L'un des logements préférés des voyageurs sur ...  \n",
      "4  L'un des logements préférés des voyageurs sur ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/mj9skg6x7j38ls1ncwhc9s400000gn/T/ipykernel_53864/3476901757.py:3: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  merged_dfs_linkedin[[\"Type of Accomodation\", \"Address\"]] = merged_dfs_linkedin[\"Type of accommodation and address\"].str.split('-',1, expand = True)\n"
     ]
    }
   ],
   "source": [
    "## DATA MANIPULATION AND CLEANING \n",
    "\n",
    "merged_dfs_linkedin[[\"Type of Accomodation\", \"Address\"]] = merged_dfs_linkedin[\"Type of accommodation and address\"].str.split('-',1, expand = True)\n",
    "merged_dfs_linkedin = merged_dfs_linkedin.drop(columns =[\"Type of accommodation and address\"])\n",
    "\n",
    "col_to_move = merged_dfs_linkedin.pop(\"Type of Accomodation\")\n",
    "merged_dfs_linkedin.insert(1,\"Type of Accomodation\",col_to_move)\n",
    "\n",
    "col_to_move = merged_dfs_linkedin.pop(\"Address\")\n",
    "merged_dfs_linkedin.insert(2,\"Address\", col_to_move)\n",
    "#check the result\n",
    "print(merged_dfs_linkedin.head())\n",
    "\n",
    "#save the result in a new csv file\n",
    "merged_dfs_linkedin.to_csv(\"cleaned_annonces.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "#IDENTIFICATION OF THE REGIONS\n",
    "\n",
    "!pip install geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import time \n",
    "\n",
    "#geocoder confguration \n",
    "geolocator = Nominatim(user_agent=\"city_analysis\")\n",
    "\n",
    "def get_region(city):\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        location = geolocator.geocode(city, exactly_one=True)\n",
    "        if location:\n",
    "            # Usa display_name per ottenere dettagli sulla regione\n",
    "            display_name = location.raw.get('display_name', '')\n",
    "            # Suddividi i dati e cerca la regione\n",
    "            parts = display_name.split(', ')\n",
    "            if len(parts) > 2:\n",
    "                return parts[2:4]  # Ad esempio, 'Grand Est'\n",
    "            else:\n",
    "                return 'Unknown'\n",
    "        else:\n",
    "            print(f\"Impossibile trovare la città: {city}\")\n",
    "            return 'Unknown'\n",
    "    except Exception as e:\n",
    "        print(f\"Errore con la città {city}: {e}\")\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Applica la funzione alla colonna Address\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_dfs_linkedin[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_dfs_linkedin[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAddress\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_region(x) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(x) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Salva il file aggiornato\u001b[39;00m\n\u001b[1;32m      5\u001b[0m merged_dfs_linkedin\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_regions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Applica la funzione alla colonna Address\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_dfs_linkedin[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_dfs_linkedin[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAddress\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_region(x) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(x) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Salva il file aggiornato\u001b[39;00m\n\u001b[1;32m      5\u001b[0m merged_dfs_linkedin\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_regions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[54], line 9\u001b[0m, in \u001b[0;36mget_region\u001b[0;34m(city)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_region\u001b[39m(city):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m         location \u001b[38;5;241m=\u001b[39m geolocator\u001b[38;5;241m.\u001b[39mgeocode(city, exactly_one\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m location:\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;66;03m# Usa display_name per ottenere dettagli sulla regione\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Applica la funzione alla colonna Address\n",
    "merged_dfs_linkedin['Region'] = merged_dfs_linkedin['Address'].apply(lambda x: get_region(x) if pd.notnull(x) else 'Unknown')\n",
    "\n",
    "# Salva il file aggiornato\n",
    "merged_dfs_linkedin.to_csv(\"with_regions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risultato: {'place_id': 90829492, 'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright', 'osm_type': 'relation', 'osm_id': 75628, 'lat': '49.4404591', 'lon': '1.0939658', 'class': 'boundary', 'type': 'administrative', 'place_rank': 16, 'importance': 0.6847400787060492, 'addresstype': 'city', 'name': 'Rouen', 'display_name': 'Rouen, Seine-Maritime, Normandie, France métropolitaine, France', 'boundingbox': ['49.4172001', '49.4652601', '1.0300648', '1.1521157']}\n"
     ]
    }
   ],
   "source": [
    "city = \"Rouen, France\"\n",
    "location = geolocator.geocode(city, exactly_one=True)\n",
    "if location:\n",
    "    print(f\"Risultato: {location.raw}\")\n",
    "else:\n",
    "    print(\"Città non trovata.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACT THE REGION\n",
    "\n",
    "merged_dfs_linkedin = pd.read_csv(\"with_regions.csv\")\n",
    "\n",
    "\n",
    "#  Lista delle regioni francesi\n",
    "french_regions = [\n",
    "    'Auvergne-Rhône-Alpes', 'Bretagne', 'Centre-Val de Loire', 'Corse', 'Grand Est', \n",
    "    'Hauts-de-France', 'Île-de-France', 'Normandie', 'Nouvelle-Aquitaine', \n",
    "    'Occitanie', 'Pays de la Loire', 'Provence-Alpes-Côte d\\'Azur', 'Bourgogne-Franche-Comté'\n",
    "]\n",
    "\n",
    "merged_dfs_linkedin['Region'].astype(str)\n",
    "merged_dfs_linkedin['Region'].dtype\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def extract_region(text):\n",
    "    for region in french_regions:\n",
    "        if region in text:\n",
    "            return region  \n",
    "    return np.nan\n",
    "\n",
    "merged_dfs_linkedin['Extracted Region'] = merged_dfs_linkedin['Region'].apply(extract_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs_linkedin['Extracted Region'].head(20)\n",
    "\n",
    "merged_dfs_linkedin['Extracted Region'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Region Extracted Region\n",
      "13                    ['Rouen', 'Seine-Maritime']              NaN\n",
      "59                                        Unknown              NaN\n",
      "83                                        Unknown              NaN\n",
      "108                       ['Cherbourg', 'Manche']              NaN\n",
      "144    ['6354', 'Schweiz/Suisse/Svizzera/Svizra']              NaN\n",
      "145                ['Métropole de Lyon', 'Rhône']              NaN\n",
      "147    ['8260', 'Schweiz/Suisse/Svizzera/Svizra']              NaN\n",
      "148                                       Unknown              NaN\n",
      "149    ['6078', 'Schweiz/Suisse/Svizzera/Svizra']              NaN\n",
      "152    ['6078', 'Schweiz/Suisse/Svizzera/Svizra']              NaN\n",
      "153                          ['Liguria', '16031']              NaN\n",
      "158                        ['Lombardia', '22020']              NaN\n",
      "162                       ['Lleida', 'Catalunya']              NaN\n",
      "164    ['6354', 'Schweiz/Suisse/Svizzera/Svizra']              NaN\n",
      "166         ['Ortenaukreis', 'Baden-Württemberg']              NaN\n",
      "177                     ['Valais/Wallis', '3954']              NaN\n",
      "180                       ['Girona', 'Catalunya']              NaN\n",
      "184  ['Verwaltungsregion Oberland', 'Bern/Berne']              NaN\n",
      "197                                       Unknown              NaN\n",
      "258                                       Unknown              NaN\n",
      "260                     ['Albertville', 'Savoie']              NaN\n",
      "263                     ['Albertville', 'Savoie']              NaN\n",
      "331                                       Unknown              NaN\n",
      "352                           ['Alençon', 'Orne']              NaN\n",
      "362                       ['Avranches', 'Manche']              NaN\n",
      "412                                       Unknown              NaN\n"
     ]
    }
   ],
   "source": [
    "#show the rows with na\n",
    "rows_with_na = merged_dfs_linkedin[merged_dfs_linkedin['Extracted Region'].isna()][['Region', 'Extracted Region']]\n",
    "\n",
    "# Visualizza il risultato\n",
    "print(rows_with_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CLEANING THE TEXT OF REVIEWS\n",
    "\n",
    "import emoji \n",
    "\n",
    "def remove_emoji (text):\n",
    "    return emoji.replace_emoji(text, replace = '')\n",
    "\n",
    "merged_dfs_linkedin['Comments cleaned'] = merged_dfs_linkedin['Comments'].apply(remove_emoji)\n",
    "\n",
    "# Salva il risultato\n",
    "merged_dfs_linkedin.to_csv(\" 3 without_emojis.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/francescavasta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/francescavasta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "\n",
    "# Configura NLTK e spaCy\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "#!python -m spacy download fr_core_news_sm\n",
    "nlp = spacy.load('fr_core_news_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_comments(comment):\n",
    "    # Tokenizzazione\n",
    "    words = word_tokenize(comment.lower())\n",
    "    # Rimuovi stop words\n",
    "    filtered_words = [word for word in words if word not in stop_words and word.isalpha()]\n",
    "    # Lemmatizzazione\n",
    "    lemmatized_words = [nlp(word)[0].lemma_ for word in filtered_words]\n",
    "    return lemmatized_words\n",
    "\n",
    "# Applica la funzione ai commenti\n",
    "merged_dfs_linkedin['Processed Comments'] = merged_dfs_linkedin['Comments'].apply(lambda x: process_comments(x) if pd.notnull(x) else [])\n",
    "\n",
    "# Salva il risultato\n",
    "merged_dfs_linkedin.to_csv(\"5 processed_comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = '/Users/francescavasta/Desktop/ADSEM/II YEAR I SEM/UE 1 - Advanced programming/module 2 DATA VISUALIZATION/annonces csv/datasets/5 processed_comments.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicates (key columns): 0\n",
      "Empty DataFrame\n",
      "Columns: [URL, Type of Accomodation, Address, Travelers, Rooms, Bathrooms, Rating, Number of comments, Price per night, Free cancellation, Host, Host experience, Comments, Region, Extracted Region, Comments cleaned, Processed Comments]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Define the key columns to check\n",
    "key_columns = ['URL', 'Address', 'Type of Accomodation', 'Host']\n",
    "\n",
    "# Find duplicates based on the key columns\n",
    "duplicates_key = data[data.duplicated(subset=key_columns)]\n",
    "\n",
    "# Display the total number of duplicates for these key columns\n",
    "print(\"Total duplicates (key columns):\", len(duplicates_key))\n",
    "\n",
    "# Display the duplicates for these key columns\n",
    "print(duplicates_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Missing Values  Percentage (%)\n",
      "Extracted Region                  26        5.241935\n",
      "Number of comments                 9        1.814516\n",
      "Address                            2        0.403226\n",
      "URL                                0        0.000000\n",
      "Host                               0        0.000000\n",
      "Comments cleaned                   0        0.000000\n",
      "Region                             0        0.000000\n",
      "Comments                           0        0.000000\n",
      "Host experience                    0        0.000000\n",
      "Price per night                    0        0.000000\n",
      "Free cancellation                  0        0.000000\n",
      "Type of Accomodation               0        0.000000\n",
      "Rating                             0        0.000000\n",
      "Bathrooms                          0        0.000000\n",
      "Rooms                              0        0.000000\n",
      "Travelers                          0        0.000000\n",
      "Processed Comments                 0        0.000000\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_data = data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
    "\n",
    "# Display a summary\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_data,\n",
    "    \"Percentage (%)\": missing_percentage\n",
    "}).sort_values(by=\"Missing Values\", ascending=False)\n",
    "\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 17)\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['· 1 chambre' '· Studio' '· 2 chambres' '· 3 chambres' '· 3 lits'\n",
      " '· 4 chambres' '· 5 chambres' '· 8 chambres' '· 1 lit']\n"
     ]
    }
   ],
   "source": [
    "# Display unique values in Rooms\n",
    "print(data['Rooms'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "· 1 chambre     169\n",
      "· 2 chambres    159\n",
      "· 3 chambres     99\n",
      "· Studio         23\n",
      "· 4 chambres      4\n",
      "· 1 lit           3\n",
      "· 3 lits          2\n",
      "· 5 chambres      2\n",
      "· 8 chambres      1\n",
      "Name: Rooms, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display unique values in Rooms\n",
    "print(data['Rooms'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROOMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Rooms Room Type  Number of Rooms\n",
      "0  · 1 chambre      Room              1.0\n",
      "1  · 1 chambre      Room              1.0\n",
      "2  · 1 chambre      Room              1.0\n",
      "3  · 1 chambre      Room              1.0\n",
      "4  · 1 chambre      Room              1.0\n"
     ]
    }
   ],
   "source": [
    "# Function to determine the type of accommodation\n",
    "def extract_room_type(room_desc):\n",
    "    if pd.isna(room_desc) or 'not specified' in room_desc.lower():\n",
    "        return 'Unknown'\n",
    "    elif 'studio' in room_desc.lower():\n",
    "        return 'Studio'\n",
    "    elif 'chambre' in room_desc.lower():\n",
    "        return 'Room'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Function to extract the number of rooms\n",
    "def extract_number_of_rooms(room_desc):\n",
    "    if pd.isna(room_desc) or 'not specified' in room_desc.lower():\n",
    "        return None\n",
    "    elif 'studio' in room_desc.lower():\n",
    "        return 0\n",
    "    elif 'chambre' in room_desc.lower():\n",
    "        # Extract the first digit corresponding to the number of rooms\n",
    "        match = pd.Series(room_desc).str.extract(r'(\\d+)')\n",
    "        return int(match[0].iloc[0]) if not match.empty and pd.notna(match[0].iloc[0]) else None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the functions\n",
    "data['Room Type'] = data['Rooms'].apply(extract_room_type)\n",
    "data['Number of Rooms'] = data['Rooms'].apply(extract_number_of_rooms)\n",
    "\n",
    "# Check the results\n",
    "print(data[['Rooms', 'Room Type', 'Number of Rooms']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Room' 'Studio' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "print(data['Room Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room       434\n",
      "Studio      23\n",
      "Unknown      5\n",
      "Name: Room Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Room Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    457.000000\n",
      "mean       1.789934\n",
      "std        0.948029\n",
      "min        0.000000\n",
      "25%        1.000000\n",
      "50%        2.000000\n",
      "75%        2.000000\n",
      "max        8.000000\n",
      "Name: Number of Rooms, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data['Number of Rooms'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Number of Rooms'] = data['Number of Rooms'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superhôte · Hôte depuis 2 ans                       63\n",
      "Superhôte · Hôte depuis 3 ans                       53\n",
      "Superhôte · Hôte depuis 4 ans                       37\n",
      "Superhôte · Hôte depuis 6 ans                       30\n",
      "Superhôte · Hôte depuis 5 ans                       28\n",
      "Superhôte · Hôte depuis 1 an                        25\n",
      "Superhôte · Hôte depuis 7 ans                       19\n",
      "Superhôte · Hôte depuis 8 ans                       19\n",
      "Superhôte · 6 mois d'expérience en tant qu'hôte     16\n",
      "Hôte depuis 7 ans                                   14\n",
      "Superhôte · 5 mois d'expérience en tant qu'hôte     12\n",
      "Superhôte · Hôte depuis 9 ans                       11\n",
      "Hôte depuis 5 ans                                   11\n",
      "Superhôte · 10 mois d'expérience en tant qu'hôte    10\n",
      "Superhôte · Hôte depuis 10 ans                      10\n",
      "1 mois d'expérience en tant qu'hôte                  9\n",
      "Hôte depuis 2 ans                                    9\n",
      "Superhôte · 7 mois d'expérience en tant qu'hôte      7\n",
      "Hôte depuis 4 ans                                    7\n",
      "Superhôte · Hôte depuis 11 ans                       6\n",
      "Hôte depuis 10 ans                                   6\n",
      "Hôte depuis 3 ans                                    6\n",
      "Hôte depuis 1 an                                     5\n",
      "Hôte depuis 6 ans                                    5\n",
      "Superhôte · 8 mois d'expérience en tant qu'hôte      5\n",
      "Superhôte · 11 mois d'expérience en tant qu'hôte     5\n",
      "Nouvel hôte                                          4\n",
      "Superhôte · Hôte depuis 12 ans                       4\n",
      "4 mois d'expérience en tant qu'hôte                  4\n",
      "3 mois d'expérience en tant qu'hôte                  4\n",
      "2 mois d'expérience en tant qu'hôte                  3\n",
      "5 mois d'expérience en tant qu'hôte                  2\n",
      "Superhôte · 9 mois d'expérience en tant qu'hôte      2\n",
      "Hôte depuis 9 ans                                    2\n",
      "Superhôte · 4 mois d'expérience en tant qu'hôte      2\n",
      "8 mois d'expérience en tant qu'hôte                  2\n",
      "Hôte depuis 8 ans                                    2\n",
      "Superhôte · 3 mois d'expérience en tant qu'hôte      1\n",
      "9 mois d'expérience en tant qu'hôte                  1\n",
      "Superhôte · 2 mois d'expérience en tant qu'hôte      1\n",
      "Name: Host experience, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Host experience'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price per night  Number of comments  Bathrooms\n",
      "0            115.0                61.0        1.0\n",
      "1            152.0               417.0        1.0\n",
      "2            120.0               165.0        1.0\n",
      "3             32.0               457.0        1.0\n",
      "4            207.0                84.0        2.0\n"
     ]
    }
   ],
   "source": [
    "# Function to clean the price per night\n",
    "def clean_price(price_desc):\n",
    "    if pd.isna(price_desc) or price_desc.lower() in ['not specified']:\n",
    "        return None\n",
    "    try:\n",
    "        return float(price_desc.replace('€', '').strip())\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Function to clean the number of comments\n",
    "def clean_comments(comment_desc):\n",
    "    if pd.isna(comment_desc):\n",
    "        return None\n",
    "    try:\n",
    "        return int(pd.Series(comment_desc).str.extract(r'(\\d+)')[0].iloc[0])\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "# Function to clean the number of bathrooms\n",
    "def clean_bathrooms(bathroom_desc):\n",
    "    if pd.isna(bathroom_desc):\n",
    "        return None\n",
    "    try:\n",
    "        match = pd.Series(bathroom_desc).str.extract(r'(\\d+)')\n",
    "        return int(match[0].iloc[0]) if not match.empty and pd.notna(match[0].iloc[0]) else None\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "# Apply the cleaning functions\n",
    "data['Price per night'] = data['Price per night'].apply(clean_price)\n",
    "data['Number of comments'] = data['Number of comments'].apply(clean_comments)\n",
    "data['Bathrooms'] = data['Bathrooms'].apply(clean_bathrooms)\n",
    "\n",
    "# Check the cleaned columns\n",
    "print(data[['Price per night', 'Number of comments', 'Bathrooms']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the type of accomodation, applied only to the cells that contain 'Logement entier :'\n",
    "def clean_accomodation_type(room_desc):\n",
    "    if isinstance(room_desc, str) and 'Logement entier :' in room_desc:\n",
    "        # Split the string after ': ' and take the last part\n",
    "        return room_desc.split(': ')[-1]\n",
    "    return room_desc  # Return the original value if 'Logement entier :' is not present\n",
    "\n",
    "# Function to clean the type of accomodation, applied only to the cells that contain 'Logement entier :'\n",
    "def extract_host_name(text):\n",
    "    if isinstance(text, str) and 'Hôte :' in text:\n",
    "        # Split the string after ': ' and take the last part\n",
    "        return text.split(': ')[-1]\n",
    "    return text  # Return the original value if 'Logement entier :' is not present\n",
    "\n",
    "# Function to clean the host experience including \"depuis\" if present\n",
    "def extract_host_experience(text):\n",
    "    if isinstance(text, str):\n",
    "        # Regex to extract \"depuis\" and the duration\n",
    "        match = pd.Series(text).str.extract(r'((?:depuis\\s*)?\\d+\\s(?:mois|ans))')\n",
    "        \n",
    "        # Extract the full match (e.g., \"depuis 10 ans\" or \"5 mois\")\n",
    "        return match[0].iloc[0] if not match.empty and pd.notna(match[0].iloc[0]) else None\n",
    "    return None\n",
    "\n",
    "# Function to clean the host experience including \"depuis\" if present\n",
    "def annulation_gratuite(text):\n",
    "    if pd.notna(text) and 'Annulation gratuite' in text:\n",
    "        return 'yes'\n",
    "    else: \n",
    "        return 'no'\n",
    "\n",
    "# apply the function \n",
    "data['Type of Accomodation'] = data['Type of Accomodation'].apply(clean_accomodation_type)\n",
    "data['Host'] = data['Host'].apply(extract_host_name)\n",
    "data['Host experience'] = data['Host experience'].apply(extract_host_experience)\n",
    "data['Free cancellation cleaned'] = data['Free cancellation'].apply(annulation_gratuite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Type of Accomodation                Host Host experience  \\\n",
      "0              cabane               Julien          5 mois   \n",
      "1              Grotte             Sandrine   depuis 10 ans   \n",
      "2         appartement               Claire    depuis 7 ans   \n",
      "3      maison d'hôtes           Christophe    depuis 5 ans   \n",
      "4         hébergement   Amandine Et Maxime    depuis 3 ans   \n",
      "\n",
      "                       Free cancellation Free cancellation cleaned  \n",
      "0   Annulation gratuite avant le 21 janv                       yes  \n",
      "1                          Not specified                        no  \n",
      "2                   Claire est Superhôte                        no  \n",
      "3   Annulation gratuite avant le 11 janv                       yes  \n",
      "4  Annulation gratuite pendant 48 heures                       yes  \n"
     ]
    }
   ],
   "source": [
    "# Check the cleaned columns\n",
    "print(data[['Type of Accomodation', 'Host', 'Host experience', 'Free cancellation', 'Free cancellation cleaned']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the number of travelers\n",
    "def clean_travelers(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    try:\n",
    "        match = pd.Series(text).str.extract(r'(\\d+)')\n",
    "        return int(match[0].iloc[0]) if not match.empty and pd.notna(match[0].iloc[0]) else None\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "    \n",
    "# Function to clean the rating and extract the decimal part\n",
    "def clean_rating(text):\n",
    "    if pd.isna(text):  # Check if the value is NaN\n",
    "        return None\n",
    "    try:\n",
    "        # Extract the decimal number with a comma\n",
    "        match = pd.Series(text).str.extract(r'(\\d+,\\d+ |\\d+)')  # Regex to capture the decimal number\n",
    "        # Convert to float by replacing the comma with a dot\n",
    "        return float(match[0].iloc[0].replace(',', '.')) if not match.empty and pd.notna(match[0].iloc[0]) else None\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "#apply the function \n",
    "data['Travelers'] = data['Travelers'].apply(clean_travelers)\n",
    "data['Rating'] = data['Rating'].apply(clean_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL', 'Type of Accomodation', 'Address', 'Travelers', 'Rooms',\n",
       "       'Bathrooms', 'Rating', 'Number of comments', 'Price per night',\n",
       "       'Free cancellation', 'Host', 'Host experience', 'Comments', 'Region',\n",
       "       'Extracted Region', 'Comments cleaned', 'Processed Comments',\n",
       "       'Room Type', 'Number of Rooms', 'Free cancellation cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of Accomodation</th>\n",
       "      <th>Address</th>\n",
       "      <th>Travelers</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Number of comments</th>\n",
       "      <th>Price per night</th>\n",
       "      <th>Host</th>\n",
       "      <th>Host experience</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Extracted Region</th>\n",
       "      <th>Comments cleaned</th>\n",
       "      <th>Processed Comments</th>\n",
       "      <th>Room Type</th>\n",
       "      <th>Number of Rooms</th>\n",
       "      <th>Free cancellation cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cabane</td>\n",
       "      <td>Traînel, France</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>61.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Julien</td>\n",
       "      <td>5 mois</td>\n",
       "      <td>Ce logement fait partie des 5 % de logements p...</td>\n",
       "      <td>Grand Est</td>\n",
       "      <td>Ce logement fait partie des 5 % de logements p...</td>\n",
       "      <td>['logement', 'faire', 'partie', 'logement', 'p...</td>\n",
       "      <td>Room</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grotte</td>\n",
       "      <td>Noyers-sur-Cher, France</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>417.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>Sandrine</td>\n",
       "      <td>depuis 10 ans</td>\n",
       "      <td>Ma copine et moi avons passe 3 jours dans cett...</td>\n",
       "      <td>Centre-Val de Loire</td>\n",
       "      <td>Ma copine et moi avons passe 3 jours dans cett...</td>\n",
       "      <td>['copine', 'passer', 'jour', 'ce', 'caverne', ...</td>\n",
       "      <td>Room</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appartement</td>\n",
       "      <td>Rouen, France</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>165.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Claire</td>\n",
       "      <td>depuis 7 ans</td>\n",
       "      <td>L'un des logements préférés des voyageurs sur ...</td>\n",
       "      <td>Normandie</td>\n",
       "      <td>L'un des logements préférés des voyageurs sur ...</td>\n",
       "      <td>['logement', 'préférer', 'voyageur', 'airbnb',...</td>\n",
       "      <td>Room</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maison d'hôtes</td>\n",
       "      <td>Ussel, France</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>457.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Christophe</td>\n",
       "      <td>depuis 5 ans</td>\n",
       "      <td>L'un des logements préférés des voyageurs sur ...</td>\n",
       "      <td>Nouvelle-Aquitaine</td>\n",
       "      <td>L'un des logements préférés des voyageurs sur ...</td>\n",
       "      <td>['logement', 'préférer', 'voyageur', 'airbnb',...</td>\n",
       "      <td>Room</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hébergement</td>\n",
       "      <td>Valras-Plage, France</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>84.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>Amandine Et Maxime</td>\n",
       "      <td>depuis 3 ans</td>\n",
       "      <td>L'un des logements préférés des voyageurs sur ...</td>\n",
       "      <td>Occitanie</td>\n",
       "      <td>L'un des logements préférés des voyageurs sur ...</td>\n",
       "      <td>['logement', 'préférer', 'voyageur', 'airbnb',...</td>\n",
       "      <td>Room</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type of Accomodation                   Address  Travelers  Bathrooms  \\\n",
       "0              cabane            Traînel, France          2        1.0   \n",
       "1              Grotte    Noyers-sur-Cher, France          4        1.0   \n",
       "2         appartement              Rouen, France          2        1.0   \n",
       "3      maison d'hôtes              Ussel, France          2        1.0   \n",
       "4         hébergement       Valras-Plage, France          2        2.0   \n",
       "\n",
       "   Rating  Number of comments  Price per night                Host  \\\n",
       "0    4.97                61.0            115.0              Julien   \n",
       "1    4.82               417.0            152.0            Sandrine   \n",
       "2    4.93               165.0            120.0              Claire   \n",
       "3    4.93               457.0             32.0          Christophe   \n",
       "4    4.93                84.0            207.0  Amandine Et Maxime   \n",
       "\n",
       "  Host experience                                           Comments  \\\n",
       "0          5 mois  Ce logement fait partie des 5 % de logements p...   \n",
       "1   depuis 10 ans  Ma copine et moi avons passe 3 jours dans cett...   \n",
       "2    depuis 7 ans  L'un des logements préférés des voyageurs sur ...   \n",
       "3    depuis 5 ans  L'un des logements préférés des voyageurs sur ...   \n",
       "4    depuis 3 ans  L'un des logements préférés des voyageurs sur ...   \n",
       "\n",
       "      Extracted Region                                   Comments cleaned  \\\n",
       "0            Grand Est  Ce logement fait partie des 5 % de logements p...   \n",
       "1  Centre-Val de Loire  Ma copine et moi avons passe 3 jours dans cett...   \n",
       "2            Normandie  L'un des logements préférés des voyageurs sur ...   \n",
       "3   Nouvelle-Aquitaine  L'un des logements préférés des voyageurs sur ...   \n",
       "4            Occitanie  L'un des logements préférés des voyageurs sur ...   \n",
       "\n",
       "                                  Processed Comments Room Type  \\\n",
       "0  ['logement', 'faire', 'partie', 'logement', 'p...      Room   \n",
       "1  ['copine', 'passer', 'jour', 'ce', 'caverne', ...      Room   \n",
       "2  ['logement', 'préférer', 'voyageur', 'airbnb',...      Room   \n",
       "3  ['logement', 'préférer', 'voyageur', 'airbnb',...      Room   \n",
       "4  ['logement', 'préférer', 'voyageur', 'airbnb',...      Room   \n",
       "\n",
       "   Number of Rooms Free cancellation cleaned  \n",
       "0                1                       yes  \n",
       "1                1                        no  \n",
       "2                1                        no  \n",
       "3                1                       yes  \n",
       "4                1                       yes  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['URL', 'Rooms','Free cancellation','Region']\n",
    "data = data.drop(columns=(columns_to_drop))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Room Type', 'Number of Rooms', 'Free cancellation cleaned']\n",
      "  Type of Accomodation                   Address  Travelers Room Type  \\\n",
      "0              cabane            Traînel, France          2      Room   \n",
      "1              Grotte    Noyers-sur-Cher, France          4      Room   \n",
      "2         appartement              Rouen, France          2      Room   \n",
      "3      maison d'hôtes              Ussel, France          2      Room   \n",
      "4         hébergement       Valras-Plage, France          2      Room   \n",
      "\n",
      "   Number of Rooms Free cancellation cleaned  Bathrooms  Rating  \\\n",
      "0                1                       yes        1.0    4.97   \n",
      "1                1                        no        1.0    4.82   \n",
      "2                1                        no        1.0    4.93   \n",
      "3                1                       yes        1.0    4.93   \n",
      "4                1                       yes        2.0    4.93   \n",
      "\n",
      "   Number of comments  Price per night                Host Host experience  \\\n",
      "0                61.0            115.0              Julien          5 mois   \n",
      "1               417.0            152.0            Sandrine   depuis 10 ans   \n",
      "2               165.0            120.0              Claire    depuis 7 ans   \n",
      "3               457.0             32.0          Christophe    depuis 5 ans   \n",
      "4                84.0            207.0  Amandine Et Maxime    depuis 3 ans   \n",
      "\n",
      "                                            Comments     Extracted Region  \\\n",
      "0  Ce logement fait partie des 5 % de logements p...            Grand Est   \n",
      "1  Ma copine et moi avons passe 3 jours dans cett...  Centre-Val de Loire   \n",
      "2  L'un des logements préférés des voyageurs sur ...            Normandie   \n",
      "3  L'un des logements préférés des voyageurs sur ...   Nouvelle-Aquitaine   \n",
      "4  L'un des logements préférés des voyageurs sur ...            Occitanie   \n",
      "\n",
      "                                    Comments cleaned  \\\n",
      "0  Ce logement fait partie des 5 % de logements p...   \n",
      "1  Ma copine et moi avons passe 3 jours dans cett...   \n",
      "2  L'un des logements préférés des voyageurs sur ...   \n",
      "3  L'un des logements préférés des voyageurs sur ...   \n",
      "4  L'un des logements préférés des voyageurs sur ...   \n",
      "\n",
      "                                  Processed Comments  \n",
      "0  ['logement', 'faire', 'partie', 'logement', 'p...  \n",
      "1  ['copine', 'passer', 'jour', 'ce', 'caverne', ...  \n",
      "2  ['logement', 'préférer', 'voyageur', 'airbnb',...  \n",
      "3  ['logement', 'préférer', 'voyageur', 'airbnb',...  \n",
      "4  ['logement', 'préférer', 'voyageur', 'airbnb',...  \n"
     ]
    }
   ],
   "source": [
    "#reorder columns\n",
    "cols = data.columns.tolist()\n",
    "\n",
    "# extract the last tree columns that we want to move\n",
    "last_three_cols = cols[-3:]\n",
    "print(last_three_cols)\n",
    "\n",
    "# new order of columns\n",
    "new_order = cols[:3] + last_three_cols + cols[3:-3]\n",
    "\n",
    "# Riordiniamo il DataFrame\n",
    "data = data[new_order]\n",
    "\n",
    "# Verifica il risultato\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'cleaned_airbnb_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned file\n",
    "data.to_csv('cleaned_airbnb_data.csv', index=False, encoding='utf-8')\n",
    "print(\"Cleaned data saved to 'cleaned_airbnb_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type of Accomodation          0\n",
       "Address                       0\n",
       "Travelers                     0\n",
       "Room Type                     0\n",
       "Number of Rooms               0\n",
       "Free cancellation cleaned     0\n",
       "Bathrooms                     4\n",
       "Rating                        9\n",
       "Number of comments            1\n",
       "Price per night               9\n",
       "Host                          0\n",
       "Host experience              34\n",
       "Comments                      0\n",
       "Extracted Region              0\n",
       "Comments cleaned              0\n",
       "Processed Comments            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
